<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zheyuan "Brian" Zhang</title>

    <meta name="author" content="Zheyuan Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zheyuan "Brian" Zhang
                </p>
                <p>I am an incoming Ph.D. student in Computer Science at the <a href="https://www.jhu.edu/" target=&ldquo;blank&rdquo;>Johns Hopkins University</a>, advised by Prof. <a href="https://www.tshu.io/" target=&ldquo;blank&rdquo;>Tianmin Shu</a> and Prof. <a href="https://danielkhashabi.com/" target=&ldquo;blank&rdquo;>Daniel Khashabi</a>.</p> 
                <p>I graduated with an M.S. in Robotics from the <a href="https://robotics.umich.edu/" target=&ldquo;blank&rdquo;>Robotics Institute</a> and a Graduate Certificate in Cognitive Science from the <a href="https://lsa.umich.edu/weinberginstitute" target=&ldquo;blank&rdquo;>Weinberg Institute for Cognitive Science</a> at the <a href="https://umich.edu/" target=&ldquo;blank&rdquo;>University of Michigan</a>. I was a research assistant at the <a href="https://sled.eecs.umich.edu/" target=&ldquo;blank&rdquo;>Situated Language and Embodied Dialogue (SLED)</a> lab, advised by Prof. <a href="https://web.eecs.umich.edu/~chaijy/" target=&ldquo;blank&rdquo;>Joyce Chai</a>. I was also fortunate to work with Prof. <a href="https://people.csail.mit.edu/ganchuang/" target=&ldquo;blank&rdquo;>Chuang Gan</a>, Prof. <a href="https://web.eecs.umich.edu/~honglak/" target=&ldquo;blank&rdquo;>Honglak Lee</a>, Prof. <a href="https://home.ttic.edu/~freda/" target=&ldquo;blank&rdquo;>Freda Shi</a>, Prof. <a href="https://www.cse.msu.edu/~kordjams/" target=&ldquo;blank&rdquo;>Parisa Kordjamshidi</a>. I did a BS in Computer Science from <a href="https://www.umass.edu/" target=&ldquo;blank&rdquo;>UMass Amherst</a>, <a href="https://www.cics.umass.edu/" target=&ldquo;blank&rdquo;>College of Information &amp; Computer Sciences</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:zheyuan@umich.edu">Email</a> &nbsp;/&nbsp;
                  <a href="pdf/cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=hYMYxOQAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/zheyuanzhang99">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/cozheyuanzhangde">Github</a> &nbsp;/&nbsp;
                  <a href="./readinglist.html">Reading List</a>
                </p>
              </td>
              <td style="padding:2.5%;width:25%;max-width:25%">
                <a href="img/photo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="img/photo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am fascinated with understanding natural intelligence through computational modeling. My current research interests are centered around <strong>Embodied AI</strong>, <strong>Multimodality</strong>, and <strong>Language</strong>, with the goal to create <i>Scalable Cognitive Agents</i> that perceive, act, and learn like humans in physical and virtual worlds.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul id="news-list">
                <li> [2025.06] üöÄ We released <a href="https://virtual-community-ai.github.io/">Virtual Community</a> ‚Äî a simulator where humans ü§ù robots cohabit in dynamic, open societies with unlimited characters, robots, and cities!</li>
                <li> [2025.03] I will join <a href="https://www.jhu.edu/">Johns Hopkins University</a> in Fall 2025.</li>
                <li> [2025.01] <a href="https://arxiv.org/abs/2410.17385">COMFORT</a> accepted to ICLR 2025 as <span style="color: red;">Oral Presentation</span>.</li>

                <li id="toggle-li">
                  <button id="toggle-btn" style="border: none; background: none; cursor: pointer;">‚ñ∂</button>
                </li>

                <div id="hidden-news">
                  <li> [2025.01] <a href="https://arxiv.org/abs/2404.10775">COMBO</a> accepted to ICLR 2025.</li>
                  <li> [2024.11] <a href="https://arxiv.org/abs/2410.18806">One paper</a> accepted to COLING 2025.</li>
                  <li> [2024.10] <a href="https://spatial-comfort.github.io/">COMFORT</a> accepted to Pluralistic Alignment Workshop @ NeurIPS 2024.</li>
                  <li> [2024.10] <a href="https://arxiv.org/abs/2311.17041">EILeV</a> accepted to Video-Language Models @ NeurIPS 2024.</li>
                  <li> [2024.09] <a href="https://arxiv.org/abs/2311.17041">EILeV</a> accepted to EMNLP 2024.</li>
                  <li> [2023.10] <a href="https://arxiv.org/abs/2310.18364">HAR</a> accepted to EMNLP 2023.</li>
                </div>
              </ul>
            </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Selected</h2>
              * ‚Üí equal contribution
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr style="background-color:#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/vico.png" alt="img_vico" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://spatial-comfort.github.io/">
                  <span class="papertitle">Virtual Community: An Open World for Humans, Robots, and Society</span></a>
              <br>
              Qinhong Zhou*, Hongxin Zhang*, Xiangye Lin*, <strong>Zheyuan Zhang*</strong>, Yutian Chen, Wenjun Liu, Zunzhe Zhang, Sunli Chen, Lixing Fang, Qiushi Lyu, Xinyu Sun, Jincheng Yang, Zeyuan Wang, Bao Chi Dang, Zhehuan Chen, Daksha Ladia, Jiageng Liu, Chuang Gan
              <br>
              <a href="https://virtual-community-ai.github.io/">Project Page</a>
              |
              <a href="https://github.com/UMass-Embodied-AGI/Virtual-Community">Code</a>
              </td>
            </tr>

            <tr style="background-color:#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/comfort.jpg" alt="img_comfort" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://spatial-comfort.github.io/">
                  <span class="papertitle">Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities</span></a>
              <br>
              <strong>Zheyuan Zhang*</strong>, Fengyuan Hu*, Jayjun Lee*, Freda Shi, Parisa Kordjamshidi, Joyce Chai, Ziqiao Ma
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2025 <a style="color:red"><strong>(Oral)</strong></a>
              <br>
              <em>Pluralistic Alignment @ NeurIPS 2024</em>
              <br>
              <a href="https://spatial-comfort.github.io/">Project Page</a>
              |
              <a href="https://arxiv.org/abs/2410.17385">Paper</a>
              |
              <a href="https://github.com/sled-group/COMFORT">Code</a>
              |
              <a href="https://huggingface.co/datasets/sled-umich/COMFORT">Dataset</a>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/combo.jpg" alt="img_combo" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://vis-www.cs.umass.edu/combo/">
                  <span class="papertitle">COMBO: Compositional World Models for Embodied Multi-Agent Cooperation</span></a>
              <br>
              Hongxin Zhang*, Zeyuan Wang*, Qiushi Lyu*, <strong>Zheyuan Zhang</strong>, Sunli Chen, Tianmin Shu, Yilun Du, Chuang Gan
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2025
              <br>
              <a href="https://vis-www.cs.umass.edu/combo/">Project Page</a>
              |
              <a href="https://arxiv.org/abs/2404.10775">Paper</a>
              |
              <a href="https://github.com/UMass-Foundation-Model/COMBO">Code</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Preprints</h2>
              * ‚Üí equal contribution
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/pmd.jpg" alt="img_comfort" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2412.11927">
                  <span class="papertitle">Explainable Procedural Mistake Detection</span></a>
              <br>
              Shane Storks, Itamar Bar-Yossef, Yayuan Li, <strong>Zheyuan Zhang</strong>, Jason J. Corso, Joyce Chai
              <br>
              <em>arXiv</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2412.11927">Paper</a>
              |
              <a href="https://github.com/sled-group/">Code</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Publications</h2>
              * ‚Üí equal contribution
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/minsym.jpg" alt="img_combo" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2410.18806">
                  <span class="papertitle">A Combinatorial Approach to Neural Emergent Communication</span></a>
              <br>
              <strong>Zheyuan Zhang</strong>
              <br>
              <em>International Conference on Computational Linguistics (COLING)</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2410.18806">Paper</a>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/eilev.jpg" alt="img_eilev" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2311.17041">
                  <span class="papertitle">EILeV: Eliciting In-Context Learning in Vision-Language Models for Videos Through Curated Data Distributional Properties</span>
                </a>
                <br>
                Keunwoo Peter Yu, <strong>Zheyuan Zhang</strong>, Fengyuan Hu, Shane Storks, Joyce Chai
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2024
                <br>
                <em>Video-Language Models @ NeurIPS 2024</em>
                <br>
                <a href="https://arxiv.org/abs/2311.17041">Paper</a>
                |
                <a href="https://github.com/yukw777/EILEV">Code</a>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/har.jpg" alt="img_har" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2310.18364">
                  <span class="papertitle">From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent Physical Commonsense Reasoning</span>
                </a>
                <br>
                <strong>Zheyuan Zhang*</strong>, Shane Storks*, Fengyuan Hu, Sungryull Sohn, Moontae Lee, Honglak Lee, Joyce Chai
                <br>
                <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2310.18364">Paper</a>
                |
                <a href="https://github.com/sled-group/Heuristic-Analytic-Reasoning">Code</a>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/lsvrg.jpg" alt="img_lsvrg" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9757984">
                  <span class="papertitle">Low-cost Solution for Vision-based Robotic Grasping</span>
                </a>
                <br>
                <strong>Zheyuan Zhang</strong>, Huiliang Shang
                <br>
                <em>International Conference on Networking Systems of AI (INSAI), IEEE Computer Society</em>, 2021 <a style="color:red"><strong>(Second Prize)</strong></a>
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/9757984">Paper</a>
                |
                <a href="https://github.com/cozheyuanzhangde/Invariant-TemplateMatching">Code (110 <i class="fa-solid fa-star"></i>)</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Other Projects</h2>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/botlab.jpg" alt="img_botlab" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="pdf/botlab.pdf">
                  <span class="papertitle">Bot Lab: Autonomous Ground Vehicle from Low-level Control, SLAM to Planning and Exploration</span>
                </a>
                <br>
                <strong>Zheyuan Zhang</strong>, Yu Zhu, Manu Aatitya Raajan Priyadharshini, Thirumalaesh Ashokkumar
                <br>
                <em>ROB 550 (Robotic Systems Laboratory), University of Michigan</em>, 2022
                <br>
                <a href="pdf/botlab.pdf">Paper</a>
              </td>
            </tr>
          </tbody></table>

          
          <table width="100%" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Teaching</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="img/umich.png" alt="img_umich" width="160" height="160" style="border-style: none">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                Graduate Student Instructor (GSI), EECS 492 (Introduction to Artificial Intelligence), University of Michigan
                <br>
                Winter 2024, Fall 2023
                <br>
                <br>
                Textbook: <a href="http://aima.cs.berkeley.edu/">Artificial Intelligence: A Modern Approach, 4th Edition</a>
              </td>
            </tr>
            
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Academic Services</h2>
              <ul>
                <li>Conference Reviewer: ICLR 2025, NeurIPS 2024 Workshop</li>
              </ul>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>My hobbies</h2>
            <ul>
              <li>Movie & TV: Suspense dramas and fantasy animes; Fan of "A Mortal's Journey" (Âá°‰∫∫‰øÆ‰ªô‰º†).</li>
              <li>Gaming: I used to play competitive FPS games like Rainbow Six Siege (R6s), Valorant and Apex Legends. I achieved the highest ranks in R6s for 10 seasons (5x champion, 5x diamond).</li>
              <li>Bodybuilding: Lift weights and train physique.</li>
              <li>HiFi: I am an audiophile. Some HiFi devices I have:
                <ul>
                  <li>IEM: Astell&Kern x Vision Ears Aura</li>
                  <li>IEM: Raosound Black Oriolus 1st Edition</li>
                  <li>Headphone: HiFiMAN Edition X V1</li>
                  <li>DAP: Astell&Kern A&ultima SP3000</li>
                  <li>DAP: Lotoo PAW Gold</li>
                  <li>DAP: Sony PCM D100</li>
                </ul>
              </li>
              <li>Fragrance: Collect fragrances.</li>
            </ul>
          </td>
        </tr>
      </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:left;font-size:small;">
                  <p>Source code borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.</p>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>


<script>
  const toggleBtn = document.getElementById('toggle-btn');
  const hiddenNews = document.getElementById('hidden-news');
  let expanded = false;

  // Initialize hidden
  window.onload = function() {
    hiddenNews.style.display = 'none';
  };

  toggleBtn.addEventListener('click', function() {
    expanded = !expanded;
    if (expanded) {
      hiddenNews.style.display = 'block';
      toggleBtn.textContent = '‚ñº';
    } else {
      hiddenNews.style.display = 'none';
      toggleBtn.textContent = '‚ñ∂';
    }
  });
</script>